{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obiettivo:  \n",
    "Creare un modello in grado di prevedere se un passeggero del Titanic sarebbe sopravvissuto o meno al tragico naufragio, in base a caratteristiche come età, sesso, classe di viaggio e altre variabili disponibili nel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carico ed importo tutte le librerie necessarie allo svolgimento del progetto, \n",
    "# in particolare verranno utilizzate le seguenti librerie:  \n",
    "# Pandas, sklearn, matplotlib e seaborn\n",
    "\n",
    "# Utilizzando Pandas, vado a caricare il dataset 'titanic_sub.csv' nella variabile df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('titanic_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo il target (la colonna 'Survived') dalle altre features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[['Sex', 'Age', 'Pclass', 'Embarked']]\n",
    "y=df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vedo che ci sono delle variabili categoriche di tipo 'Object' che devo trasformare per essere \"digerite\" dal modello.\n",
    "#  \n",
    "# Pertanto utilizzo LabelEncoder che, seguendo l'ordine alfabetico, trasformerà la categoria 'Sex' da 'Female'\\'Male' a '0'\\'1'.\n",
    "# In generale LabelEncoder viene preferito per trasformazioni binarie o per trasformazioni categoriche ordinali, ovvero dove le categorie da trasformare hanno un loro 'ordine di importanza'\n",
    "\n",
    "# Per quanto riguarda la categoria 'Embarked' contenente i valori C,S,Q (che si riferisce al porto di imbarco e che non hanno un implicito ordine di importanza) utilizzo get_dummies di Pandas \n",
    "# perchè utilizza una codifica one-hot, ovvero trasforma una variabile categoriale non ordinata in più colonne binarie (tante quante sono i valori attribuibili alla feature in esame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "X['Sex']=le.fit_transform(X['Sex'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.get_dummies(X, columns=['Embarked'], dtype=int)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo 'X' e 'y' in train set (75% dei dati totali) e test set (25% dei dati totali) \n",
    "# impostando 'random_state'=0 per garantire la riproducibilità degli esperimenti.\n",
    "# Questo ci assicura che lo stesso codice produca sempre lo stesso risultato ogni volta che viene eseguito.\n",
    "\n",
    "# Suddivido ulteriormente il train set, il 25% dei dati verrà destinato al set di validazione\n",
    "#  che ci permetterà di:\n",
    "    #  validare il modello su dati non visti prima di testarlo sul test set, \n",
    "    #  andando a sperimentare diversi valori degli iperparametri, così da individuare quello più efficace al fine\n",
    "    #  di prevenire problemi di fitting regolando la complessità del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test= train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "print(X_train1.shape, y_train1.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train1, y_train1, test_size=0.25, random_state=0)\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modello: albero di decisione. \n",
    "\n",
    "Validare la profondità con i valori: 2, 5, 10, 25, profondità max.  \n",
    "\n",
    "Metrica di valutazione: Accuratezza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imposto il modello come 'DecisionTreeClassifier':\n",
    "# Lo addestro con i dati di 'training' e lo vado a validare su quelli di 'validazione' facendo variare \n",
    "# la profondità dell'albero con il parametro k.\n",
    "# Per ogni valore di k valuto l'accuratezza del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [2,5,10,25,None]:\n",
    "    tree=DecisionTreeClassifier(max_depth=k, random_state=0)\n",
    "    tree.fit(X_train,y_train)\n",
    "    predictions=tree.predict(X_val)\n",
    "    validation_accuracy=accuracy_score(y_val, predictions)\n",
    "    print(f'Accuratezza modello per k={k}: {validation_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne risulta che l'accuratezza maggiore ce lo dà il valore k=10 con una accuratezza pari a 82%\n",
    "\n",
    "# imposto quindi il modello finale con il valore trovato dell'iperparametro k e vado a testarlo sui dati nuovi,\n",
    "#  mai visti dal modello, ovvero sul test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "best_model.fit(X_train,y_train)\n",
    "predictions_bm=best_model.predict(X_test)\n",
    "validation_accuracy_bm=accuracy_score(y_test, predictions_bm)\n",
    "print(f'Accuratezza modello per k={k}: {validation_accuracy_bm:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolando l'accuratezza del modello finale mi trovo il valore 79%\n",
    "#  che è più basso di quanto trovato nei test di validazione ma comunque in linea\n",
    "#   il che ci fa concludere che il modello si comporta bene sui dati mai visti prima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZZAZIONE DELL'ALBERO E INTERPRETAZIONE\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(60,40))\n",
    "plot_tree(best_model, feature_names=X.columns, class_names=[\"Non sopravvissuto\", \"Sopravvissuto\"], filled=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
